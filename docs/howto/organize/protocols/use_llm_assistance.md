# How to Use LLM Assistance  
> Support for reflection and documentation — not a source of authority.

---

## Purpose
Language models (LLMs) can support writing, summarizing, and refining circle materials.  
They are tools for **clarity, consistency, and accessibility**, not substitutes for practice or discernment.

Used carefully, they help the circle document and evolve without centralizing authority.

---

## Guidelines

### 1. Absolutely Fine to Use
Using an LLM to:
- Proofread or simplify language  
- Format notes, summaries, or templates  
- Suggest structure for documentation or publications  
- Draft or edit living documents before group review  

LLMs are collaborators in refinement — never in decision-making.

---

### 2. Protect Privacy and Integrity
- Do **not** share personal names, private reflections, or identifiable information.  
- Replace names with roles or initials when summarizing (e.g., *Participant A*, *Facilitator*).  
- Remove sensitive data before uploading or prompting.  
- Never delegate interpersonal communication to an LLM.

---

### 3. Proofread Everything
Always **review and correct** outputs before sharing.  
Check for:
- Tone consistency (neutral, non-promotional)  
- Accuracy of meaning  
- Alignment with Practice Circle ethos  

If the text feels artificial, polish it manually before inclusion.

---

### 4. Support, Not Authority
LLMs can **suggest** language but cannot interpret experience, resolve conflict, or speak for the group.  
They serve as **custodians of clarity**, not **creators of meaning**.  
Final judgment always rests with human participants.

---

## Summary

Use LLMs as **assistants for articulation**, not as decision-makers or voices of authority.  
They help us write clearly, not think for us.

> Practice remains human.  
> The machine helps us see — not decide.

---

## Resources

**[LLM Custom Prompts](llm_custom_prompts.md)** — Ready-to-use prompts for configuring custom GPTs and other language models to align with Practice Circle principles.
